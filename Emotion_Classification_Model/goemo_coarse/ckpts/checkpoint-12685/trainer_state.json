{
  "best_global_step": 5074,
  "best_metric": 0.6488283321267652,
  "best_model_checkpoint": "goemo_coarse/ckpts/checkpoint-5074",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 12685,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07883326763894363,
      "grad_norm": 3.2848641872406006,
      "learning_rate": 3.1363278171788814e-06,
      "loss": 1.6677,
      "step": 200
    },
    {
      "epoch": 0.15766653527788727,
      "grad_norm": 6.060243129730225,
      "learning_rate": 6.288416075650119e-06,
      "loss": 1.3854,
      "step": 400
    },
    {
      "epoch": 0.2364998029168309,
      "grad_norm": 6.201382637023926,
      "learning_rate": 9.440504334121356e-06,
      "loss": 1.1073,
      "step": 600
    },
    {
      "epoch": 0.31533307055577453,
      "grad_norm": 7.799809455871582,
      "learning_rate": 1.2592592592592593e-05,
      "loss": 1.004,
      "step": 800
    },
    {
      "epoch": 0.3941663381947182,
      "grad_norm": 11.287813186645508,
      "learning_rate": 1.5744680851063832e-05,
      "loss": 0.9526,
      "step": 1000
    },
    {
      "epoch": 0.4729996058336618,
      "grad_norm": 8.41968822479248,
      "learning_rate": 1.889676910953507e-05,
      "loss": 0.948,
      "step": 1200
    },
    {
      "epoch": 0.5518328734726055,
      "grad_norm": 11.247171401977539,
      "learning_rate": 1.9993601440476744e-05,
      "loss": 0.9087,
      "step": 1400
    },
    {
      "epoch": 0.6306661411115491,
      "grad_norm": 9.254823684692383,
      "learning_rate": 1.9958792979158453e-05,
      "loss": 0.9061,
      "step": 1600
    },
    {
      "epoch": 0.7094994087504927,
      "grad_norm": 7.784363746643066,
      "learning_rate": 1.9893824688008717e-05,
      "loss": 0.8584,
      "step": 1800
    },
    {
      "epoch": 0.7883326763894364,
      "grad_norm": 8.96823501586914,
      "learning_rate": 1.9798893321052808e-05,
      "loss": 0.8862,
      "step": 2000
    },
    {
      "epoch": 0.86716594402838,
      "grad_norm": 6.006433963775635,
      "learning_rate": 1.9674286374363695e-05,
      "loss": 0.8756,
      "step": 2200
    },
    {
      "epoch": 0.9459992116673236,
      "grad_norm": 5.5576629638671875,
      "learning_rate": 1.952038121539101e-05,
      "loss": 0.8399,
      "step": 2400
    },
    {
      "epoch": 1.0,
      "eval_f1_anger": 0.5726762320648784,
      "eval_f1_fear": 0.6216216216216216,
      "eval_f1_joy": 0.8040037243947858,
      "eval_f1_neutral": 0.6150931480896747,
      "eval_f1_sadness": 0.5283018867924528,
      "eval_f1_surprise": 0.6138763197586727,
      "eval_loss": 0.8361973762512207,
      "eval_macro_f1": 0.6259288221203476,
      "eval_micro_f1": 0.6780487804878049,
      "eval_runtime": 21.9707,
      "eval_samples_per_second": 251.926,
      "eval_steps_per_second": 15.748,
      "step": 2537
    },
    {
      "epoch": 1.0248324793062673,
      "grad_norm": 6.2767534255981445,
      "learning_rate": 1.9337643940117928e-05,
      "loss": 0.8146,
      "step": 2600
    },
    {
      "epoch": 1.103665746945211,
      "grad_norm": 6.937366962432861,
      "learning_rate": 1.9126627961507005e-05,
      "loss": 0.7711,
      "step": 2800
    },
    {
      "epoch": 1.1824990145841545,
      "grad_norm": 6.65930700302124,
      "learning_rate": 1.888797233350985e-05,
      "loss": 0.7359,
      "step": 3000
    },
    {
      "epoch": 1.2613322822230981,
      "grad_norm": 8.675283432006836,
      "learning_rate": 1.8622399815716283e-05,
      "loss": 0.7679,
      "step": 3200
    },
    {
      "epoch": 1.3401655498620417,
      "grad_norm": 7.690675258636475,
      "learning_rate": 1.8330714684504108e-05,
      "loss": 0.7337,
      "step": 3400
    },
    {
      "epoch": 1.4189988175009853,
      "grad_norm": 8.036149024963379,
      "learning_rate": 1.8013800297318367e-05,
      "loss": 0.7658,
      "step": 3600
    },
    {
      "epoch": 1.4978320851399292,
      "grad_norm": 5.742856979370117,
      "learning_rate": 1.7672616417456537e-05,
      "loss": 0.7247,
      "step": 3800
    },
    {
      "epoch": 1.5766653527788725,
      "grad_norm": 4.917097568511963,
      "learning_rate": 1.730819630746152e-05,
      "loss": 0.7459,
      "step": 4000
    },
    {
      "epoch": 1.6554986204178164,
      "grad_norm": 5.135720729827881,
      "learning_rate": 1.6921643599924903e-05,
      "loss": 0.7525,
      "step": 4200
    },
    {
      "epoch": 1.73433188805676,
      "grad_norm": 6.374814510345459,
      "learning_rate": 1.6514128955177166e-05,
      "loss": 0.7396,
      "step": 4400
    },
    {
      "epoch": 1.8131651556957036,
      "grad_norm": 9.60517692565918,
      "learning_rate": 1.6086886515986927e-05,
      "loss": 0.7567,
      "step": 4600
    },
    {
      "epoch": 1.8919984233346472,
      "grad_norm": 8.222044944763184,
      "learning_rate": 1.5641210170006007e-05,
      "loss": 0.7469,
      "step": 4800
    },
    {
      "epoch": 1.9708316909735908,
      "grad_norm": 8.127662658691406,
      "learning_rate": 1.5178449631279354e-05,
      "loss": 0.7437,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_f1_anger": 0.5985104942450914,
      "eval_f1_fear": 0.627906976744186,
      "eval_f1_joy": 0.8147424945081767,
      "eval_f1_neutral": 0.6624168514412417,
      "eval_f1_sadness": 0.5836065573770491,
      "eval_f1_surprise": 0.6057866184448463,
      "eval_loss": 0.7902426719665527,
      "eval_macro_f1": 0.6488283321267652,
      "eval_micro_f1": 0.699728997289973,
      "eval_runtime": 21.9265,
      "eval_samples_per_second": 252.434,
      "eval_steps_per_second": 15.78,
      "step": 5074
    },
    {
      "epoch": 2.0496649586125346,
      "grad_norm": 5.624289035797119,
      "learning_rate": 1.4700006352686834e-05,
      "loss": 0.6624,
      "step": 5200
    },
    {
      "epoch": 2.128498226251478,
      "grad_norm": 7.684345722198486,
      "learning_rate": 1.4207329281695943e-05,
      "loss": 0.6242,
      "step": 5400
    },
    {
      "epoch": 2.207331493890422,
      "grad_norm": 8.742374420166016,
      "learning_rate": 1.370191047227888e-05,
      "loss": 0.5775,
      "step": 5600
    },
    {
      "epoch": 2.286164761529365,
      "grad_norm": 8.37211799621582,
      "learning_rate": 1.3185280566283258e-05,
      "loss": 0.6168,
      "step": 5800
    },
    {
      "epoch": 2.364998029168309,
      "grad_norm": 7.856390953063965,
      "learning_rate": 1.2659004157940861e-05,
      "loss": 0.5817,
      "step": 6000
    },
    {
      "epoch": 2.443831296807253,
      "grad_norm": 5.7626166343688965,
      "learning_rate": 1.2124675055552863e-05,
      "loss": 0.5747,
      "step": 6200
    },
    {
      "epoch": 2.5226645644461962,
      "grad_norm": 9.890974044799805,
      "learning_rate": 1.1583911454701382e-05,
      "loss": 0.5568,
      "step": 6400
    },
    {
      "epoch": 2.60149783208514,
      "grad_norm": 11.188156127929688,
      "learning_rate": 1.1038351037605012e-05,
      "loss": 0.5793,
      "step": 6600
    },
    {
      "epoch": 2.6803310997240835,
      "grad_norm": 10.341338157653809,
      "learning_rate": 1.0489646013459878e-05,
      "loss": 0.5797,
      "step": 6800
    },
    {
      "epoch": 2.7591643673630273,
      "grad_norm": 10.705643653869629,
      "learning_rate": 9.93945811478622e-06,
      "loss": 0.5885,
      "step": 7000
    },
    {
      "epoch": 2.8379976350019707,
      "grad_norm": 11.140364646911621,
      "learning_rate": 9.389453564934008e-06,
      "loss": 0.5677,
      "step": 7200
    },
    {
      "epoch": 2.9168309026409145,
      "grad_norm": 10.393935203552246,
      "learning_rate": 8.841298031988193e-06,
      "loss": 0.5702,
      "step": 7400
    },
    {
      "epoch": 2.9956641702798583,
      "grad_norm": 11.393921852111816,
      "learning_rate": 8.296651584355603e-06,
      "loss": 0.5966,
      "step": 7600
    },
    {
      "epoch": 3.0,
      "eval_f1_anger": 0.5903141361256544,
      "eval_f1_fear": 0.6145833333333334,
      "eval_f1_joy": 0.8109371348445898,
      "eval_f1_neutral": 0.6124644099968365,
      "eval_f1_sadness": 0.5722300140252454,
      "eval_f1_surprise": 0.606516290726817,
      "eval_loss": 0.8821088671684265,
      "eval_macro_f1": 0.6345075531754129,
      "eval_micro_f1": 0.6829268292682927,
      "eval_runtime": 21.8265,
      "eval_samples_per_second": 253.591,
      "eval_steps_per_second": 15.852,
      "step": 7611
    },
    {
      "epoch": 3.0744974379188017,
      "grad_norm": 5.698948860168457,
      "learning_rate": 7.757163663310222e-06,
      "loss": 0.4526,
      "step": 7800
    },
    {
      "epoch": 3.1533307055577455,
      "grad_norm": 14.465227127075195,
      "learning_rate": 7.224468087722358e-06,
      "loss": 0.4293,
      "step": 8000
    },
    {
      "epoch": 3.232163973196689,
      "grad_norm": 10.862943649291992,
      "learning_rate": 6.700178106099671e-06,
      "loss": 0.4443,
      "step": 8200
    },
    {
      "epoch": 3.3109972408356327,
      "grad_norm": 11.447269439697266,
      "learning_rate": 6.185881510924757e-06,
      "loss": 0.455,
      "step": 8400
    },
    {
      "epoch": 3.389830508474576,
      "grad_norm": 7.82213020324707,
      "learning_rate": 5.683135830085374e-06,
      "loss": 0.4381,
      "step": 8600
    },
    {
      "epoch": 3.46866377611352,
      "grad_norm": 12.621498107910156,
      "learning_rate": 5.193463609959801e-06,
      "loss": 0.4386,
      "step": 8800
    },
    {
      "epoch": 3.5474970437524638,
      "grad_norm": 5.300405979156494,
      "learning_rate": 4.71834780444248e-06,
      "loss": 0.4372,
      "step": 9000
    },
    {
      "epoch": 3.626330311391407,
      "grad_norm": 13.97883129119873,
      "learning_rate": 4.25922728387387e-06,
      "loss": 0.4114,
      "step": 9200
    },
    {
      "epoch": 3.7051635790303505,
      "grad_norm": 8.797764778137207,
      "learning_rate": 3.817492477475819e-06,
      "loss": 0.4309,
      "step": 9400
    },
    {
      "epoch": 3.7839968466692944,
      "grad_norm": 14.402466773986816,
      "learning_rate": 3.394481162488941e-06,
      "loss": 0.4399,
      "step": 9600
    },
    {
      "epoch": 3.862830114308238,
      "grad_norm": 13.201665878295898,
      "learning_rate": 2.991474412764611e-06,
      "loss": 0.4359,
      "step": 9800
    },
    {
      "epoch": 3.9416633819471816,
      "grad_norm": 12.61063289642334,
      "learning_rate": 2.609692719080984e-06,
      "loss": 0.4461,
      "step": 10000
    },
    {
      "epoch": 4.0,
      "eval_f1_anger": 0.5863192182410424,
      "eval_f1_fear": 0.6127167630057804,
      "eval_f1_joy": 0.8073266867609552,
      "eval_f1_neutral": 0.6156693399136336,
      "eval_f1_sadness": 0.5705426356589147,
      "eval_f1_surprise": 0.5972461273666093,
      "eval_loss": 0.9841034412384033,
      "eval_macro_f1": 0.6316367951578226,
      "eval_micro_f1": 0.6816621499548329,
      "eval_runtime": 21.8515,
      "eval_samples_per_second": 253.301,
      "eval_steps_per_second": 15.834,
      "step": 10148
    },
    {
      "epoch": 4.020496649586125,
      "grad_norm": 7.101784706115723,
      "learning_rate": 2.2502922929325967e-06,
      "loss": 0.408,
      "step": 10200
    },
    {
      "epoch": 4.099329917225069,
      "grad_norm": 18.7857723236084,
      "learning_rate": 1.9143615649873738e-06,
      "loss": 0.3551,
      "step": 10400
    },
    {
      "epoch": 4.178163184864013,
      "grad_norm": 5.634706020355225,
      "learning_rate": 1.602917888815282e-06,
      "loss": 0.3515,
      "step": 10600
    },
    {
      "epoch": 4.256996452502956,
      "grad_norm": 11.628815650939941,
      "learning_rate": 1.3169044598713509e-06,
      "loss": 0.36,
      "step": 10800
    },
    {
      "epoch": 4.3358297201419,
      "grad_norm": 9.617743492126465,
      "learning_rate": 1.0571874590636932e-06,
      "loss": 0.3482,
      "step": 11000
    },
    {
      "epoch": 4.414662987780844,
      "grad_norm": 9.626769065856934,
      "learning_rate": 8.2455342955724e-07,
      "loss": 0.3542,
      "step": 11200
    },
    {
      "epoch": 4.493496255419787,
      "grad_norm": 20.17793846130371,
      "learning_rate": 6.19706894757347e-07,
      "loss": 0.3498,
      "step": 11400
    },
    {
      "epoch": 4.57232952305873,
      "grad_norm": 10.841046333312988,
      "learning_rate": 4.432682246871756e-07,
      "loss": 0.3481,
      "step": 11600
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 13.600713729858398,
      "learning_rate": 2.957717572204155e-07,
      "loss": 0.3405,
      "step": 11800
    },
    {
      "epoch": 4.729996058336618,
      "grad_norm": 17.32230567932129,
      "learning_rate": 1.776641798591394e-07,
      "loss": 0.3556,
      "step": 12000
    },
    {
      "epoch": 4.8088293259755615,
      "grad_norm": 12.911520004272461,
      "learning_rate": 8.93031769575159e-08,
      "loss": 0.3547,
      "step": 12200
    },
    {
      "epoch": 4.887662593614506,
      "grad_norm": 5.711677074432373,
      "learning_rate": 3.0956346488190126e-08,
      "loss": 0.3393,
      "step": 12400
    },
    {
      "epoch": 4.966495861253449,
      "grad_norm": 14.811084747314453,
      "learning_rate": 2.800389631905098e-09,
      "loss": 0.3749,
      "step": 12600
    },
    {
      "epoch": 5.0,
      "eval_f1_anger": 0.5890052356020943,
      "eval_f1_fear": 0.6162790697674418,
      "eval_f1_joy": 0.8060254924681344,
      "eval_f1_neutral": 0.6169429097605893,
      "eval_f1_sadness": 0.5691823899371069,
      "eval_f1_surprise": 0.5857019810508183,
      "eval_loss": 1.0460646152496338,
      "eval_macro_f1": 0.6305228464310307,
      "eval_micro_f1": 0.6807588075880758,
      "eval_runtime": 21.765,
      "eval_samples_per_second": 254.307,
      "eval_steps_per_second": 15.897,
      "step": 12685
    }
  ],
  "logging_steps": 200,
  "max_steps": 12685,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6721212889774080.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
