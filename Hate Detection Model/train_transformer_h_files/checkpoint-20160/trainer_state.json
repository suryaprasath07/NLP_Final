{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 20160,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0496031746031746,
      "grad_norm": 1.8163737058639526,
      "learning_rate": 1.995138888888889e-05,
      "loss": 0.6693,
      "step": 50
    },
    {
      "epoch": 0.0992063492063492,
      "grad_norm": 2.686349391937256,
      "learning_rate": 1.9901785714285715e-05,
      "loss": 0.6007,
      "step": 100
    },
    {
      "epoch": 0.1488095238095238,
      "grad_norm": 2.679603338241577,
      "learning_rate": 1.985218253968254e-05,
      "loss": 0.5824,
      "step": 150
    },
    {
      "epoch": 0.1984126984126984,
      "grad_norm": 3.9505865573883057,
      "learning_rate": 1.9802579365079367e-05,
      "loss": 0.5716,
      "step": 200
    },
    {
      "epoch": 0.24801587301587302,
      "grad_norm": 5.755943298339844,
      "learning_rate": 1.975297619047619e-05,
      "loss": 0.5296,
      "step": 250
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 6.862400531768799,
      "learning_rate": 1.9703373015873016e-05,
      "loss": 0.4722,
      "step": 300
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 3.1835885047912598,
      "learning_rate": 1.9654761904761905e-05,
      "loss": 0.5664,
      "step": 350
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 3.9245784282684326,
      "learning_rate": 1.960515873015873e-05,
      "loss": 0.5107,
      "step": 400
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 7.401317119598389,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.5077,
      "step": 450
    },
    {
      "epoch": 0.49603174603174605,
      "grad_norm": 4.352968692779541,
      "learning_rate": 1.950595238095238e-05,
      "loss": 0.4986,
      "step": 500
    },
    {
      "epoch": 0.5456349206349206,
      "grad_norm": 3.0907890796661377,
      "learning_rate": 1.945634920634921e-05,
      "loss": 0.5219,
      "step": 550
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 4.517261505126953,
      "learning_rate": 1.9406746031746033e-05,
      "loss": 0.5023,
      "step": 600
    },
    {
      "epoch": 0.6448412698412699,
      "grad_norm": 2.9781293869018555,
      "learning_rate": 1.9357142857142858e-05,
      "loss": 0.4857,
      "step": 650
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 3.677365303039551,
      "learning_rate": 1.9307539682539685e-05,
      "loss": 0.4934,
      "step": 700
    },
    {
      "epoch": 0.7440476190476191,
      "grad_norm": 3.3359243869781494,
      "learning_rate": 1.925793650793651e-05,
      "loss": 0.5101,
      "step": 750
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 3.328413486480713,
      "learning_rate": 1.9208333333333337e-05,
      "loss": 0.4658,
      "step": 800
    },
    {
      "epoch": 0.8432539682539683,
      "grad_norm": 3.677091598510742,
      "learning_rate": 1.915873015873016e-05,
      "loss": 0.4734,
      "step": 850
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 6.0810112953186035,
      "learning_rate": 1.9109126984126986e-05,
      "loss": 0.5145,
      "step": 900
    },
    {
      "epoch": 0.9424603174603174,
      "grad_norm": 3.401365041732788,
      "learning_rate": 1.905952380952381e-05,
      "loss": 0.4721,
      "step": 950
    },
    {
      "epoch": 0.9920634920634921,
      "grad_norm": 5.17095422744751,
      "learning_rate": 1.9009920634920634e-05,
      "loss": 0.4391,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.773697270471464,
      "eval_loss": 0.4962252676486969,
      "eval_runtime": 2.1316,
      "eval_samples_per_second": 1890.638,
      "eval_steps_per_second": 118.223,
      "step": 1008
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 2.9740443229675293,
      "learning_rate": 1.8960317460317462e-05,
      "loss": 0.384,
      "step": 1050
    },
    {
      "epoch": 1.0912698412698412,
      "grad_norm": 3.507155656814575,
      "learning_rate": 1.8910714285714286e-05,
      "loss": 0.4246,
      "step": 1100
    },
    {
      "epoch": 1.1408730158730158,
      "grad_norm": 4.54771614074707,
      "learning_rate": 1.8861111111111114e-05,
      "loss": 0.4236,
      "step": 1150
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 8.552518844604492,
      "learning_rate": 1.8811507936507938e-05,
      "loss": 0.4123,
      "step": 1200
    },
    {
      "epoch": 1.2400793650793651,
      "grad_norm": 2.751530885696411,
      "learning_rate": 1.8761904761904762e-05,
      "loss": 0.3802,
      "step": 1250
    },
    {
      "epoch": 1.2896825396825398,
      "grad_norm": 6.369096755981445,
      "learning_rate": 1.871230158730159e-05,
      "loss": 0.4301,
      "step": 1300
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 3.9658844470977783,
      "learning_rate": 1.8663690476190476e-05,
      "loss": 0.4246,
      "step": 1350
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 5.127078533172607,
      "learning_rate": 1.8614087301587304e-05,
      "loss": 0.373,
      "step": 1400
    },
    {
      "epoch": 1.4384920634920635,
      "grad_norm": 4.913084506988525,
      "learning_rate": 1.8564484126984128e-05,
      "loss": 0.4171,
      "step": 1450
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 8.315208435058594,
      "learning_rate": 1.8514880952380952e-05,
      "loss": 0.4308,
      "step": 1500
    },
    {
      "epoch": 1.5376984126984126,
      "grad_norm": 6.949559211730957,
      "learning_rate": 1.846527777777778e-05,
      "loss": 0.3716,
      "step": 1550
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 7.552481651306152,
      "learning_rate": 1.8415674603174604e-05,
      "loss": 0.4264,
      "step": 1600
    },
    {
      "epoch": 1.6369047619047619,
      "grad_norm": 6.221029758453369,
      "learning_rate": 1.836607142857143e-05,
      "loss": 0.3842,
      "step": 1650
    },
    {
      "epoch": 1.6865079365079365,
      "grad_norm": 8.973134994506836,
      "learning_rate": 1.8316468253968256e-05,
      "loss": 0.4463,
      "step": 1700
    },
    {
      "epoch": 1.7361111111111112,
      "grad_norm": 5.461731433868408,
      "learning_rate": 1.826686507936508e-05,
      "loss": 0.4239,
      "step": 1750
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 5.116355895996094,
      "learning_rate": 1.8217261904761908e-05,
      "loss": 0.3992,
      "step": 1800
    },
    {
      "epoch": 1.8353174603174605,
      "grad_norm": 8.067140579223633,
      "learning_rate": 1.8167658730158732e-05,
      "loss": 0.4194,
      "step": 1850
    },
    {
      "epoch": 1.8849206349206349,
      "grad_norm": 5.285398006439209,
      "learning_rate": 1.8118055555555556e-05,
      "loss": 0.4212,
      "step": 1900
    },
    {
      "epoch": 1.9345238095238095,
      "grad_norm": 5.533576965332031,
      "learning_rate": 1.806845238095238e-05,
      "loss": 0.4183,
      "step": 1950
    },
    {
      "epoch": 1.9841269841269842,
      "grad_norm": 5.758559226989746,
      "learning_rate": 1.8018849206349208e-05,
      "loss": 0.4051,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7704714640198511,
      "eval_loss": 0.5065866112709045,
      "eval_runtime": 2.1076,
      "eval_samples_per_second": 1912.147,
      "eval_steps_per_second": 119.568,
      "step": 2016
    },
    {
      "epoch": 2.0337301587301586,
      "grad_norm": 9.343955039978027,
      "learning_rate": 1.7969246031746032e-05,
      "loss": 0.3673,
      "step": 2050
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 8.202208518981934,
      "learning_rate": 1.7919642857142857e-05,
      "loss": 0.2826,
      "step": 2100
    },
    {
      "epoch": 2.132936507936508,
      "grad_norm": 4.835061550140381,
      "learning_rate": 1.7870039682539684e-05,
      "loss": 0.3086,
      "step": 2150
    },
    {
      "epoch": 2.1825396825396823,
      "grad_norm": 6.466001033782959,
      "learning_rate": 1.782043650793651e-05,
      "loss": 0.3051,
      "step": 2200
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 3.57285213470459,
      "learning_rate": 1.7770833333333336e-05,
      "loss": 0.2668,
      "step": 2250
    },
    {
      "epoch": 2.2817460317460316,
      "grad_norm": 5.002655506134033,
      "learning_rate": 1.772123015873016e-05,
      "loss": 0.3083,
      "step": 2300
    },
    {
      "epoch": 2.3313492063492065,
      "grad_norm": 6.879384517669678,
      "learning_rate": 1.7671626984126985e-05,
      "loss": 0.2872,
      "step": 2350
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 9.53097915649414,
      "learning_rate": 1.7622023809523812e-05,
      "loss": 0.3073,
      "step": 2400
    },
    {
      "epoch": 2.4305555555555554,
      "grad_norm": 6.011934280395508,
      "learning_rate": 1.7572420634920636e-05,
      "loss": 0.2546,
      "step": 2450
    },
    {
      "epoch": 2.4801587301587302,
      "grad_norm": 10.602505683898926,
      "learning_rate": 1.7522817460317464e-05,
      "loss": 0.2835,
      "step": 2500
    },
    {
      "epoch": 2.5297619047619047,
      "grad_norm": 11.481456756591797,
      "learning_rate": 1.7473214285714285e-05,
      "loss": 0.3439,
      "step": 2550
    },
    {
      "epoch": 2.5793650793650795,
      "grad_norm": 15.76180362701416,
      "learning_rate": 1.7423611111111113e-05,
      "loss": 0.2869,
      "step": 2600
    },
    {
      "epoch": 2.628968253968254,
      "grad_norm": 10.560348510742188,
      "learning_rate": 1.7374007936507937e-05,
      "loss": 0.2802,
      "step": 2650
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 11.71619987487793,
      "learning_rate": 1.7324404761904764e-05,
      "loss": 0.3094,
      "step": 2700
    },
    {
      "epoch": 2.7281746031746033,
      "grad_norm": 7.688663005828857,
      "learning_rate": 1.727480158730159e-05,
      "loss": 0.3082,
      "step": 2750
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 11.918423652648926,
      "learning_rate": 1.7225198412698413e-05,
      "loss": 0.3096,
      "step": 2800
    },
    {
      "epoch": 2.8273809523809526,
      "grad_norm": 7.791075229644775,
      "learning_rate": 1.717559523809524e-05,
      "loss": 0.2829,
      "step": 2850
    },
    {
      "epoch": 2.876984126984127,
      "grad_norm": 7.830275535583496,
      "learning_rate": 1.7125992063492065e-05,
      "loss": 0.3506,
      "step": 2900
    },
    {
      "epoch": 2.9265873015873014,
      "grad_norm": 8.220075607299805,
      "learning_rate": 1.707638888888889e-05,
      "loss": 0.3229,
      "step": 2950
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 8.702041625976562,
      "learning_rate": 1.7026785714285717e-05,
      "loss": 0.3264,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.771712158808933,
      "eval_loss": 0.5538873672485352,
      "eval_runtime": 2.1078,
      "eval_samples_per_second": 1911.98,
      "eval_steps_per_second": 119.558,
      "step": 3024
    },
    {
      "epoch": 3.0257936507936507,
      "grad_norm": 18.878803253173828,
      "learning_rate": 1.697718253968254e-05,
      "loss": 0.2257,
      "step": 3050
    },
    {
      "epoch": 3.0753968253968256,
      "grad_norm": 19.113645553588867,
      "learning_rate": 1.692757936507937e-05,
      "loss": 0.1592,
      "step": 3100
    },
    {
      "epoch": 3.125,
      "grad_norm": 16.366313934326172,
      "learning_rate": 1.6877976190476193e-05,
      "loss": 0.2076,
      "step": 3150
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 1.99657142162323,
      "learning_rate": 1.6828373015873017e-05,
      "loss": 0.1946,
      "step": 3200
    },
    {
      "epoch": 3.2242063492063493,
      "grad_norm": 13.127872467041016,
      "learning_rate": 1.677876984126984e-05,
      "loss": 0.1935,
      "step": 3250
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 19.71257781982422,
      "learning_rate": 1.672916666666667e-05,
      "loss": 0.2095,
      "step": 3300
    },
    {
      "epoch": 3.3234126984126986,
      "grad_norm": 15.92153263092041,
      "learning_rate": 1.6679563492063493e-05,
      "loss": 0.2451,
      "step": 3350
    },
    {
      "epoch": 3.373015873015873,
      "grad_norm": 1.3797527551651,
      "learning_rate": 1.6630952380952383e-05,
      "loss": 0.1681,
      "step": 3400
    },
    {
      "epoch": 3.4226190476190474,
      "grad_norm": 0.38163334131240845,
      "learning_rate": 1.6581349206349207e-05,
      "loss": 0.182,
      "step": 3450
    },
    {
      "epoch": 3.4722222222222223,
      "grad_norm": 17.70708465576172,
      "learning_rate": 1.653174603174603e-05,
      "loss": 0.2726,
      "step": 3500
    },
    {
      "epoch": 3.5218253968253967,
      "grad_norm": Infinity,
      "learning_rate": 1.648214285714286e-05,
      "loss": 0.2083,
      "step": 3550
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 11.313933372497559,
      "learning_rate": 1.643353174603175e-05,
      "loss": 0.2148,
      "step": 3600
    },
    {
      "epoch": 3.621031746031746,
      "grad_norm": 15.683972358703613,
      "learning_rate": 1.6383928571428573e-05,
      "loss": 0.2146,
      "step": 3650
    },
    {
      "epoch": 3.6706349206349205,
      "grad_norm": 10.8400297164917,
      "learning_rate": 1.63343253968254e-05,
      "loss": 0.2151,
      "step": 3700
    },
    {
      "epoch": 3.7202380952380953,
      "grad_norm": 33.56008529663086,
      "learning_rate": 1.6284722222222225e-05,
      "loss": 0.2048,
      "step": 3750
    },
    {
      "epoch": 3.7698412698412698,
      "grad_norm": 19.321502685546875,
      "learning_rate": 1.623511904761905e-05,
      "loss": 0.1804,
      "step": 3800
    },
    {
      "epoch": 3.8194444444444446,
      "grad_norm": 20.202577590942383,
      "learning_rate": 1.6185515873015873e-05,
      "loss": 0.2487,
      "step": 3850
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 13.502961158752441,
      "learning_rate": 1.6135912698412697e-05,
      "loss": 0.2682,
      "step": 3900
    },
    {
      "epoch": 3.9186507936507935,
      "grad_norm": 16.641475677490234,
      "learning_rate": 1.6086309523809525e-05,
      "loss": 0.1856,
      "step": 3950
    },
    {
      "epoch": 3.9682539682539684,
      "grad_norm": 0.4205056428909302,
      "learning_rate": 1.603670634920635e-05,
      "loss": 0.2136,
      "step": 4000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.760545905707196,
      "eval_loss": 0.7828438878059387,
      "eval_runtime": 2.1073,
      "eval_samples_per_second": 1912.409,
      "eval_steps_per_second": 119.585,
      "step": 4032
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 10.816838264465332,
      "learning_rate": 1.5987103174603177e-05,
      "loss": 0.1704,
      "step": 4050
    },
    {
      "epoch": 4.067460317460317,
      "grad_norm": 3.2851998805999756,
      "learning_rate": 1.59375e-05,
      "loss": 0.1135,
      "step": 4100
    },
    {
      "epoch": 4.117063492063492,
      "grad_norm": 1.110839605331421,
      "learning_rate": 1.5887896825396825e-05,
      "loss": 0.151,
      "step": 4150
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 1.9742151498794556,
      "learning_rate": 1.5838293650793653e-05,
      "loss": 0.0873,
      "step": 4200
    },
    {
      "epoch": 4.216269841269841,
      "grad_norm": 25.743846893310547,
      "learning_rate": 1.5788690476190477e-05,
      "loss": 0.1258,
      "step": 4250
    },
    {
      "epoch": 4.265873015873016,
      "grad_norm": 6.689507961273193,
      "learning_rate": 1.5739087301587305e-05,
      "loss": 0.1572,
      "step": 4300
    },
    {
      "epoch": 4.315476190476191,
      "grad_norm": 0.09709211438894272,
      "learning_rate": 1.568948412698413e-05,
      "loss": 0.1306,
      "step": 4350
    },
    {
      "epoch": 4.365079365079365,
      "grad_norm": 7.186932563781738,
      "learning_rate": 1.5639880952380953e-05,
      "loss": 0.2148,
      "step": 4400
    },
    {
      "epoch": 4.4146825396825395,
      "grad_norm": 22.098617553710938,
      "learning_rate": 1.5590277777777778e-05,
      "loss": 0.1437,
      "step": 4450
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 32.715702056884766,
      "learning_rate": 1.5540674603174605e-05,
      "loss": 0.147,
      "step": 4500
    },
    {
      "epoch": 4.513888888888889,
      "grad_norm": 23.001840591430664,
      "learning_rate": 1.549107142857143e-05,
      "loss": 0.1757,
      "step": 4550
    },
    {
      "epoch": 4.563492063492063,
      "grad_norm": 45.79574203491211,
      "learning_rate": 1.5441468253968254e-05,
      "loss": 0.1212,
      "step": 4600
    },
    {
      "epoch": 4.613095238095238,
      "grad_norm": 1.9650293588638306,
      "learning_rate": 1.539186507936508e-05,
      "loss": 0.1542,
      "step": 4650
    },
    {
      "epoch": 4.662698412698413,
      "grad_norm": 0.954391598701477,
      "learning_rate": 1.5342261904761906e-05,
      "loss": 0.1703,
      "step": 4700
    },
    {
      "epoch": 4.712301587301587,
      "grad_norm": 1.2638639211654663,
      "learning_rate": 1.529265873015873e-05,
      "loss": 0.1764,
      "step": 4750
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 38.147178649902344,
      "learning_rate": 1.5243055555555558e-05,
      "loss": 0.1537,
      "step": 4800
    },
    {
      "epoch": 4.811507936507937,
      "grad_norm": 0.5450052618980408,
      "learning_rate": 1.5193452380952383e-05,
      "loss": 0.1637,
      "step": 4850
    },
    {
      "epoch": 4.861111111111111,
      "grad_norm": 28.541332244873047,
      "learning_rate": 1.5143849206349208e-05,
      "loss": 0.1581,
      "step": 4900
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 24.655603408813477,
      "learning_rate": 1.5094246031746034e-05,
      "loss": 0.1026,
      "step": 4950
    },
    {
      "epoch": 4.9603174603174605,
      "grad_norm": 14.057701110839844,
      "learning_rate": 1.5045634920634922e-05,
      "loss": 0.1634,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.7555831265508685,
      "eval_loss": 1.1509829759597778,
      "eval_runtime": 2.1102,
      "eval_samples_per_second": 1909.728,
      "eval_steps_per_second": 119.417,
      "step": 5040
    },
    {
      "epoch": 5.009920634920635,
      "grad_norm": 0.43529605865478516,
      "learning_rate": 1.4996031746031747e-05,
      "loss": 0.2252,
      "step": 5050
    },
    {
      "epoch": 5.059523809523809,
      "grad_norm": 26.65067481994629,
      "learning_rate": 1.4946428571428573e-05,
      "loss": 0.115,
      "step": 5100
    },
    {
      "epoch": 5.109126984126984,
      "grad_norm": 3.766160488128662,
      "learning_rate": 1.4896825396825398e-05,
      "loss": 0.1025,
      "step": 5150
    },
    {
      "epoch": 5.158730158730159,
      "grad_norm": 6.537167549133301,
      "learning_rate": 1.4847222222222224e-05,
      "loss": 0.0953,
      "step": 5200
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 57.98316955566406,
      "learning_rate": 1.479761904761905e-05,
      "loss": 0.1032,
      "step": 5250
    },
    {
      "epoch": 5.257936507936508,
      "grad_norm": 10.36756420135498,
      "learning_rate": 1.4748015873015875e-05,
      "loss": 0.0893,
      "step": 5300
    },
    {
      "epoch": 5.307539682539683,
      "grad_norm": 0.0858340784907341,
      "learning_rate": 1.4698412698412701e-05,
      "loss": 0.1059,
      "step": 5350
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 38.30769348144531,
      "learning_rate": 1.4648809523809524e-05,
      "loss": 0.1002,
      "step": 5400
    },
    {
      "epoch": 5.406746031746032,
      "grad_norm": 26.286542892456055,
      "learning_rate": 1.459920634920635e-05,
      "loss": 0.0559,
      "step": 5450
    },
    {
      "epoch": 5.4563492063492065,
      "grad_norm": 0.9551935791969299,
      "learning_rate": 1.4549603174603176e-05,
      "loss": 0.1127,
      "step": 5500
    },
    {
      "epoch": 5.505952380952381,
      "grad_norm": 3.324836492538452,
      "learning_rate": 1.45e-05,
      "loss": 0.1092,
      "step": 5550
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 30.078433990478516,
      "learning_rate": 1.4450396825396826e-05,
      "loss": 0.1073,
      "step": 5600
    },
    {
      "epoch": 5.60515873015873,
      "grad_norm": 0.37028801441192627,
      "learning_rate": 1.4400793650793652e-05,
      "loss": 0.1072,
      "step": 5650
    },
    {
      "epoch": 5.654761904761905,
      "grad_norm": 1.7112510204315186,
      "learning_rate": 1.4351190476190478e-05,
      "loss": 0.1332,
      "step": 5700
    },
    {
      "epoch": 5.704365079365079,
      "grad_norm": 55.52506637573242,
      "learning_rate": 1.4301587301587304e-05,
      "loss": 0.0806,
      "step": 5750
    },
    {
      "epoch": 5.753968253968254,
      "grad_norm": 34.65270233154297,
      "learning_rate": 1.4251984126984128e-05,
      "loss": 0.1038,
      "step": 5800
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 4.392791271209717,
      "learning_rate": 1.4202380952380954e-05,
      "loss": 0.0958,
      "step": 5850
    },
    {
      "epoch": 5.853174603174603,
      "grad_norm": 11.169096946716309,
      "learning_rate": 1.415277777777778e-05,
      "loss": 0.1642,
      "step": 5900
    },
    {
      "epoch": 5.902777777777778,
      "grad_norm": 6.091921806335449,
      "learning_rate": 1.4103174603174606e-05,
      "loss": 0.1,
      "step": 5950
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.6316770315170288,
      "learning_rate": 1.4053571428571428e-05,
      "loss": 0.1242,
      "step": 6000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.750620347394541,
      "eval_loss": 1.3763536214828491,
      "eval_runtime": 2.1114,
      "eval_samples_per_second": 1908.708,
      "eval_steps_per_second": 119.353,
      "step": 6048
    },
    {
      "epoch": 6.001984126984127,
      "grad_norm": 15.690503120422363,
      "learning_rate": 1.4003968253968254e-05,
      "loss": 0.0837,
      "step": 6050
    },
    {
      "epoch": 6.051587301587301,
      "grad_norm": 10.011004447937012,
      "learning_rate": 1.395436507936508e-05,
      "loss": 0.0752,
      "step": 6100
    },
    {
      "epoch": 6.101190476190476,
      "grad_norm": 56.22309112548828,
      "learning_rate": 1.3904761904761905e-05,
      "loss": 0.0821,
      "step": 6150
    },
    {
      "epoch": 6.150793650793651,
      "grad_norm": 0.045253753662109375,
      "learning_rate": 1.385515873015873e-05,
      "loss": 0.0414,
      "step": 6200
    },
    {
      "epoch": 6.200396825396825,
      "grad_norm": 0.19856701791286469,
      "learning_rate": 1.3805555555555556e-05,
      "loss": 0.0515,
      "step": 6250
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.14679700136184692,
      "learning_rate": 1.3755952380952382e-05,
      "loss": 0.0311,
      "step": 6300
    },
    {
      "epoch": 6.299603174603175,
      "grad_norm": 12.937481880187988,
      "learning_rate": 1.3706349206349208e-05,
      "loss": 0.0628,
      "step": 6350
    },
    {
      "epoch": 6.349206349206349,
      "grad_norm": 34.197566986083984,
      "learning_rate": 1.3656746031746033e-05,
      "loss": 0.0689,
      "step": 6400
    },
    {
      "epoch": 6.398809523809524,
      "grad_norm": 0.029638314619660378,
      "learning_rate": 1.3607142857142859e-05,
      "loss": 0.0754,
      "step": 6450
    },
    {
      "epoch": 6.448412698412699,
      "grad_norm": 0.05689220875501633,
      "learning_rate": 1.3557539682539684e-05,
      "loss": 0.0661,
      "step": 6500
    },
    {
      "epoch": 6.4980158730158735,
      "grad_norm": 2.4745678901672363,
      "learning_rate": 1.350793650793651e-05,
      "loss": 0.081,
      "step": 6550
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 0.014952233992516994,
      "learning_rate": 1.3458333333333335e-05,
      "loss": 0.0406,
      "step": 6600
    },
    {
      "epoch": 6.597222222222222,
      "grad_norm": 61.576454162597656,
      "learning_rate": 1.3408730158730159e-05,
      "loss": 0.0677,
      "step": 6650
    },
    {
      "epoch": 6.646825396825397,
      "grad_norm": 62.23102569580078,
      "learning_rate": 1.3359126984126985e-05,
      "loss": 0.1247,
      "step": 6700
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 46.85199737548828,
      "learning_rate": 1.330952380952381e-05,
      "loss": 0.0888,
      "step": 6750
    },
    {
      "epoch": 6.746031746031746,
      "grad_norm": 0.04709804803133011,
      "learning_rate": 1.3259920634920635e-05,
      "loss": 0.0523,
      "step": 6800
    },
    {
      "epoch": 6.795634920634921,
      "grad_norm": 19.238576889038086,
      "learning_rate": 1.3210317460317461e-05,
      "loss": 0.095,
      "step": 6850
    },
    {
      "epoch": 6.845238095238095,
      "grad_norm": 0.056896910071372986,
      "learning_rate": 1.3160714285714287e-05,
      "loss": 0.0858,
      "step": 6900
    },
    {
      "epoch": 6.89484126984127,
      "grad_norm": 91.5989761352539,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0894,
      "step": 6950
    },
    {
      "epoch": 6.944444444444445,
      "grad_norm": 43.77949905395508,
      "learning_rate": 1.3061507936507937e-05,
      "loss": 0.0995,
      "step": 7000
    },
    {
      "epoch": 6.994047619047619,
      "grad_norm": 2.5482282638549805,
      "learning_rate": 1.3011904761904763e-05,
      "loss": 0.0997,
      "step": 7050
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.7518610421836228,
      "eval_loss": 1.440792441368103,
      "eval_runtime": 2.112,
      "eval_samples_per_second": 1908.149,
      "eval_steps_per_second": 119.319,
      "step": 7056
    },
    {
      "epoch": 7.0436507936507935,
      "grad_norm": 6.675509929656982,
      "learning_rate": 1.2962301587301589e-05,
      "loss": 0.0618,
      "step": 7100
    },
    {
      "epoch": 7.093253968253968,
      "grad_norm": 15.960314750671387,
      "learning_rate": 1.2912698412698415e-05,
      "loss": 0.0739,
      "step": 7150
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.021997934207320213,
      "learning_rate": 1.286309523809524e-05,
      "loss": 0.0383,
      "step": 7200
    },
    {
      "epoch": 7.192460317460317,
      "grad_norm": 0.026330463588237762,
      "learning_rate": 1.2814484126984129e-05,
      "loss": 0.0617,
      "step": 7250
    },
    {
      "epoch": 7.242063492063492,
      "grad_norm": 0.47380268573760986,
      "learning_rate": 1.2764880952380953e-05,
      "loss": 0.0441,
      "step": 7300
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 0.16293378174304962,
      "learning_rate": 1.2715277777777779e-05,
      "loss": 0.0407,
      "step": 7350
    },
    {
      "epoch": 7.341269841269841,
      "grad_norm": 0.21929419040679932,
      "learning_rate": 1.2665674603174605e-05,
      "loss": 0.1121,
      "step": 7400
    },
    {
      "epoch": 7.390873015873016,
      "grad_norm": 2.1448862552642822,
      "learning_rate": 1.261607142857143e-05,
      "loss": 0.0649,
      "step": 7450
    },
    {
      "epoch": 7.440476190476191,
      "grad_norm": 0.14598025381565094,
      "learning_rate": 1.2566468253968255e-05,
      "loss": 0.0562,
      "step": 7500
    },
    {
      "epoch": 7.490079365079365,
      "grad_norm": 75.06816101074219,
      "learning_rate": 1.2516865079365081e-05,
      "loss": 0.0686,
      "step": 7550
    },
    {
      "epoch": 7.5396825396825395,
      "grad_norm": 68.3064956665039,
      "learning_rate": 1.2467261904761905e-05,
      "loss": 0.034,
      "step": 7600
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 21.260812759399414,
      "learning_rate": 1.2417658730158731e-05,
      "loss": 0.0932,
      "step": 7650
    },
    {
      "epoch": 7.638888888888889,
      "grad_norm": 0.2309289276599884,
      "learning_rate": 1.2368055555555555e-05,
      "loss": 0.0641,
      "step": 7700
    },
    {
      "epoch": 7.688492063492063,
      "grad_norm": 6.986818313598633,
      "learning_rate": 1.2318452380952381e-05,
      "loss": 0.0717,
      "step": 7750
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 0.016777286306023598,
      "learning_rate": 1.2268849206349207e-05,
      "loss": 0.059,
      "step": 7800
    },
    {
      "epoch": 7.787698412698413,
      "grad_norm": 24.467205047607422,
      "learning_rate": 1.2219246031746033e-05,
      "loss": 0.075,
      "step": 7850
    },
    {
      "epoch": 7.837301587301587,
      "grad_norm": 0.06750980764627457,
      "learning_rate": 1.2169642857142857e-05,
      "loss": 0.0386,
      "step": 7900
    },
    {
      "epoch": 7.886904761904762,
      "grad_norm": 0.012011238373816013,
      "learning_rate": 1.2120039682539683e-05,
      "loss": 0.0483,
      "step": 7950
    },
    {
      "epoch": 7.936507936507937,
      "grad_norm": 0.08883485943078995,
      "learning_rate": 1.207043650793651e-05,
      "loss": 0.0859,
      "step": 8000
    },
    {
      "epoch": 7.986111111111111,
      "grad_norm": 0.01513407938182354,
      "learning_rate": 1.2020833333333335e-05,
      "loss": 0.0678,
      "step": 8050
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.7518610421836228,
      "eval_loss": 1.641204595565796,
      "eval_runtime": 2.114,
      "eval_samples_per_second": 1906.378,
      "eval_steps_per_second": 119.208,
      "step": 8064
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.012194168753921986,
      "learning_rate": 1.1971230158730161e-05,
      "loss": 0.0676,
      "step": 8100
    },
    {
      "epoch": 8.08531746031746,
      "grad_norm": 0.012230881489813328,
      "learning_rate": 1.1921626984126985e-05,
      "loss": 0.0609,
      "step": 8150
    },
    {
      "epoch": 8.134920634920634,
      "grad_norm": 7.4141645431518555,
      "learning_rate": 1.187202380952381e-05,
      "loss": 0.0576,
      "step": 8200
    },
    {
      "epoch": 8.18452380952381,
      "grad_norm": 100.43490600585938,
      "learning_rate": 1.1822420634920636e-05,
      "loss": 0.0378,
      "step": 8250
    },
    {
      "epoch": 8.234126984126984,
      "grad_norm": 26.494714736938477,
      "learning_rate": 1.177281746031746e-05,
      "loss": 0.0142,
      "step": 8300
    },
    {
      "epoch": 8.283730158730158,
      "grad_norm": 104.66395568847656,
      "learning_rate": 1.1723214285714286e-05,
      "loss": 0.0551,
      "step": 8350
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 102.61270904541016,
      "learning_rate": 1.1673611111111112e-05,
      "loss": 0.0491,
      "step": 8400
    },
    {
      "epoch": 8.382936507936508,
      "grad_norm": 52.66849899291992,
      "learning_rate": 1.1624007936507938e-05,
      "loss": 0.0615,
      "step": 8450
    },
    {
      "epoch": 8.432539682539682,
      "grad_norm": 49.30717849731445,
      "learning_rate": 1.1574404761904764e-05,
      "loss": 0.0521,
      "step": 8500
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 16.490468978881836,
      "learning_rate": 1.1524801587301588e-05,
      "loss": 0.0488,
      "step": 8550
    },
    {
      "epoch": 8.531746031746032,
      "grad_norm": 0.6034480929374695,
      "learning_rate": 1.1475198412698414e-05,
      "loss": 0.0332,
      "step": 8600
    },
    {
      "epoch": 8.581349206349206,
      "grad_norm": 0.6737266182899475,
      "learning_rate": 1.142559523809524e-05,
      "loss": 0.0264,
      "step": 8650
    },
    {
      "epoch": 8.630952380952381,
      "grad_norm": 0.016029799357056618,
      "learning_rate": 1.1376984126984128e-05,
      "loss": 0.056,
      "step": 8700
    },
    {
      "epoch": 8.680555555555555,
      "grad_norm": 0.15676066279411316,
      "learning_rate": 1.1327380952380954e-05,
      "loss": 0.0375,
      "step": 8750
    },
    {
      "epoch": 8.73015873015873,
      "grad_norm": 0.2711458206176758,
      "learning_rate": 1.1277777777777778e-05,
      "loss": 0.0209,
      "step": 8800
    },
    {
      "epoch": 8.779761904761905,
      "grad_norm": 0.00848071463406086,
      "learning_rate": 1.1228174603174604e-05,
      "loss": 0.049,
      "step": 8850
    },
    {
      "epoch": 8.829365079365079,
      "grad_norm": 8.44615650177002,
      "learning_rate": 1.117857142857143e-05,
      "loss": 0.0607,
      "step": 8900
    },
    {
      "epoch": 8.878968253968253,
      "grad_norm": 0.016787089407444,
      "learning_rate": 1.1128968253968256e-05,
      "loss": 0.0581,
      "step": 8950
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.040009964257478714,
      "learning_rate": 1.1079365079365082e-05,
      "loss": 0.0274,
      "step": 9000
    },
    {
      "epoch": 8.978174603174603,
      "grad_norm": 1.8435721397399902,
      "learning_rate": 1.1029761904761906e-05,
      "loss": 0.0587,
      "step": 9050
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.758560794044665,
      "eval_loss": 1.665614366531372,
      "eval_runtime": 2.1143,
      "eval_samples_per_second": 1906.05,
      "eval_steps_per_second": 119.187,
      "step": 9072
    },
    {
      "epoch": 9.027777777777779,
      "grad_norm": 0.04158341512084007,
      "learning_rate": 1.0980158730158732e-05,
      "loss": 0.0504,
      "step": 9100
    },
    {
      "epoch": 9.077380952380953,
      "grad_norm": 0.023480093106627464,
      "learning_rate": 1.0930555555555556e-05,
      "loss": 0.031,
      "step": 9150
    },
    {
      "epoch": 9.126984126984127,
      "grad_norm": 0.009155377745628357,
      "learning_rate": 1.088095238095238e-05,
      "loss": 0.0343,
      "step": 9200
    },
    {
      "epoch": 9.176587301587302,
      "grad_norm": 0.2309962958097458,
      "learning_rate": 1.0831349206349206e-05,
      "loss": 0.0374,
      "step": 9250
    },
    {
      "epoch": 9.226190476190476,
      "grad_norm": 0.009799540974199772,
      "learning_rate": 1.0781746031746032e-05,
      "loss": 0.0414,
      "step": 9300
    },
    {
      "epoch": 9.27579365079365,
      "grad_norm": 0.009320707060396671,
      "learning_rate": 1.0732142857142858e-05,
      "loss": 0.0214,
      "step": 9350
    },
    {
      "epoch": 9.325396825396826,
      "grad_norm": 0.0073701427318155766,
      "learning_rate": 1.0682539682539684e-05,
      "loss": 0.0216,
      "step": 9400
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.012226058170199394,
      "learning_rate": 1.0632936507936508e-05,
      "loss": 0.0179,
      "step": 9450
    },
    {
      "epoch": 9.424603174603174,
      "grad_norm": 0.046975359320640564,
      "learning_rate": 1.0583333333333334e-05,
      "loss": 0.0266,
      "step": 9500
    },
    {
      "epoch": 9.47420634920635,
      "grad_norm": 0.9376949667930603,
      "learning_rate": 1.053373015873016e-05,
      "loss": 0.0575,
      "step": 9550
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 1.5519002676010132,
      "learning_rate": 1.0484126984126986e-05,
      "loss": 0.0526,
      "step": 9600
    },
    {
      "epoch": 9.573412698412698,
      "grad_norm": 1.0329477787017822,
      "learning_rate": 1.043452380952381e-05,
      "loss": 0.0387,
      "step": 9650
    },
    {
      "epoch": 9.623015873015873,
      "grad_norm": 0.012642222456634045,
      "learning_rate": 1.0384920634920636e-05,
      "loss": 0.0381,
      "step": 9700
    },
    {
      "epoch": 9.672619047619047,
      "grad_norm": 0.6266700625419617,
      "learning_rate": 1.0335317460317462e-05,
      "loss": 0.0372,
      "step": 9750
    },
    {
      "epoch": 9.722222222222221,
      "grad_norm": 0.005659379530698061,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.0116,
      "step": 9800
    },
    {
      "epoch": 9.771825396825397,
      "grad_norm": 0.028824876993894577,
      "learning_rate": 1.023611111111111e-05,
      "loss": 0.0225,
      "step": 9850
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.00518887210637331,
      "learning_rate": 1.0186507936507937e-05,
      "loss": 0.0748,
      "step": 9900
    },
    {
      "epoch": 9.871031746031747,
      "grad_norm": 0.0029318290762603283,
      "learning_rate": 1.0136904761904763e-05,
      "loss": 0.0132,
      "step": 9950
    },
    {
      "epoch": 9.920634920634921,
      "grad_norm": 0.015216413885354996,
      "learning_rate": 1.0087301587301589e-05,
      "loss": 0.0658,
      "step": 10000
    },
    {
      "epoch": 9.970238095238095,
      "grad_norm": 0.006340267136693001,
      "learning_rate": 1.0037698412698413e-05,
      "loss": 0.0525,
      "step": 10050
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.7578163771712159,
      "eval_loss": 1.7336034774780273,
      "eval_runtime": 2.1084,
      "eval_samples_per_second": 1911.384,
      "eval_steps_per_second": 119.521,
      "step": 10080
    },
    {
      "epoch": 10.01984126984127,
      "grad_norm": 0.007022549398243427,
      "learning_rate": 9.988095238095239e-06,
      "loss": 0.0505,
      "step": 10100
    },
    {
      "epoch": 10.069444444444445,
      "grad_norm": 0.020232640206813812,
      "learning_rate": 9.938492063492065e-06,
      "loss": 0.0164,
      "step": 10150
    },
    {
      "epoch": 10.119047619047619,
      "grad_norm": 0.0106740677729249,
      "learning_rate": 9.88888888888889e-06,
      "loss": 0.0134,
      "step": 10200
    },
    {
      "epoch": 10.168650793650794,
      "grad_norm": 0.06645432114601135,
      "learning_rate": 9.839285714285715e-06,
      "loss": 0.0103,
      "step": 10250
    },
    {
      "epoch": 10.218253968253968,
      "grad_norm": 0.149348646402359,
      "learning_rate": 9.78968253968254e-06,
      "loss": 0.0266,
      "step": 10300
    },
    {
      "epoch": 10.267857142857142,
      "grad_norm": 0.039483219385147095,
      "learning_rate": 9.740079365079365e-06,
      "loss": 0.0297,
      "step": 10350
    },
    {
      "epoch": 10.317460317460318,
      "grad_norm": 0.3932208716869354,
      "learning_rate": 9.690476190476191e-06,
      "loss": 0.0365,
      "step": 10400
    },
    {
      "epoch": 10.367063492063492,
      "grad_norm": 92.45552062988281,
      "learning_rate": 9.640873015873017e-06,
      "loss": 0.0478,
      "step": 10450
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 0.004151963163167238,
      "learning_rate": 9.591269841269843e-06,
      "loss": 0.0341,
      "step": 10500
    },
    {
      "epoch": 10.466269841269842,
      "grad_norm": 2.477079391479492,
      "learning_rate": 9.541666666666669e-06,
      "loss": 0.0045,
      "step": 10550
    },
    {
      "epoch": 10.515873015873016,
      "grad_norm": 0.007127769291400909,
      "learning_rate": 9.492063492063493e-06,
      "loss": 0.0538,
      "step": 10600
    },
    {
      "epoch": 10.56547619047619,
      "grad_norm": 0.8208247423171997,
      "learning_rate": 9.442460317460317e-06,
      "loss": 0.0307,
      "step": 10650
    },
    {
      "epoch": 10.615079365079366,
      "grad_norm": 0.003507178509607911,
      "learning_rate": 9.392857142857143e-06,
      "loss": 0.0171,
      "step": 10700
    },
    {
      "epoch": 10.66468253968254,
      "grad_norm": 0.09241852164268494,
      "learning_rate": 9.343253968253969e-06,
      "loss": 0.0395,
      "step": 10750
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.0018999188905581832,
      "learning_rate": 9.293650793650795e-06,
      "loss": 0.0325,
      "step": 10800
    },
    {
      "epoch": 10.76388888888889,
      "grad_norm": 0.0030806090217083693,
      "learning_rate": 9.244047619047621e-06,
      "loss": 0.0402,
      "step": 10850
    },
    {
      "epoch": 10.813492063492063,
      "grad_norm": 0.014986436814069748,
      "learning_rate": 9.194444444444445e-06,
      "loss": 0.0274,
      "step": 10900
    },
    {
      "epoch": 10.863095238095237,
      "grad_norm": 176.17965698242188,
      "learning_rate": 9.14484126984127e-06,
      "loss": 0.0292,
      "step": 10950
    },
    {
      "epoch": 10.912698412698413,
      "grad_norm": 0.023400558158755302,
      "learning_rate": 9.095238095238095e-06,
      "loss": 0.0304,
      "step": 11000
    },
    {
      "epoch": 10.962301587301587,
      "grad_norm": 0.21140389144420624,
      "learning_rate": 9.045634920634921e-06,
      "loss": 0.0155,
      "step": 11050
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.760545905707196,
      "eval_loss": 1.927003026008606,
      "eval_runtime": 2.1092,
      "eval_samples_per_second": 1910.681,
      "eval_steps_per_second": 119.477,
      "step": 11088
    },
    {
      "epoch": 11.011904761904763,
      "grad_norm": 0.0017355061136186123,
      "learning_rate": 8.996031746031747e-06,
      "loss": 0.0336,
      "step": 11100
    },
    {
      "epoch": 11.061507936507937,
      "grad_norm": 0.007611333392560482,
      "learning_rate": 8.946428571428573e-06,
      "loss": 0.024,
      "step": 11150
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 0.007747327908873558,
      "learning_rate": 8.896825396825398e-06,
      "loss": 0.0249,
      "step": 11200
    },
    {
      "epoch": 11.160714285714286,
      "grad_norm": 11.889347076416016,
      "learning_rate": 8.847222222222223e-06,
      "loss": 0.0234,
      "step": 11250
    },
    {
      "epoch": 11.21031746031746,
      "grad_norm": 0.0016801743768155575,
      "learning_rate": 8.797619047619048e-06,
      "loss": 0.0106,
      "step": 11300
    },
    {
      "epoch": 11.259920634920634,
      "grad_norm": 0.003272680100053549,
      "learning_rate": 8.748015873015874e-06,
      "loss": 0.0471,
      "step": 11350
    },
    {
      "epoch": 11.30952380952381,
      "grad_norm": 0.00737263448536396,
      "learning_rate": 8.6984126984127e-06,
      "loss": 0.0198,
      "step": 11400
    },
    {
      "epoch": 11.359126984126984,
      "grad_norm": 0.0020221618469804525,
      "learning_rate": 8.648809523809526e-06,
      "loss": 0.03,
      "step": 11450
    },
    {
      "epoch": 11.408730158730158,
      "grad_norm": 0.06898558139801025,
      "learning_rate": 8.59920634920635e-06,
      "loss": 0.0156,
      "step": 11500
    },
    {
      "epoch": 11.458333333333334,
      "grad_norm": 0.0010360946180298924,
      "learning_rate": 8.549603174603176e-06,
      "loss": 0.0278,
      "step": 11550
    },
    {
      "epoch": 11.507936507936508,
      "grad_norm": 0.004134651739150286,
      "learning_rate": 8.5e-06,
      "loss": 0.0131,
      "step": 11600
    },
    {
      "epoch": 11.557539682539682,
      "grad_norm": 0.03675497695803642,
      "learning_rate": 8.450396825396826e-06,
      "loss": 0.0072,
      "step": 11650
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.004488596227020025,
      "learning_rate": 8.400793650793652e-06,
      "loss": 0.026,
      "step": 11700
    },
    {
      "epoch": 11.656746031746032,
      "grad_norm": 0.009957375004887581,
      "learning_rate": 8.351190476190478e-06,
      "loss": 0.0033,
      "step": 11750
    },
    {
      "epoch": 11.706349206349206,
      "grad_norm": 0.003993400372564793,
      "learning_rate": 8.301587301587302e-06,
      "loss": 0.0342,
      "step": 11800
    },
    {
      "epoch": 11.755952380952381,
      "grad_norm": 0.005216535646468401,
      "learning_rate": 8.251984126984128e-06,
      "loss": 0.0272,
      "step": 11850
    },
    {
      "epoch": 11.805555555555555,
      "grad_norm": 0.004461212083697319,
      "learning_rate": 8.202380952380952e-06,
      "loss": 0.0226,
      "step": 11900
    },
    {
      "epoch": 11.85515873015873,
      "grad_norm": 62.36067581176758,
      "learning_rate": 8.152777777777778e-06,
      "loss": 0.0307,
      "step": 11950
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 0.006409156136214733,
      "learning_rate": 8.103174603174604e-06,
      "loss": 0.0112,
      "step": 12000
    },
    {
      "epoch": 11.954365079365079,
      "grad_norm": 121.90684509277344,
      "learning_rate": 8.05357142857143e-06,
      "loss": 0.0216,
      "step": 12050
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.7563275434243176,
      "eval_loss": 2.098219871520996,
      "eval_runtime": 2.1119,
      "eval_samples_per_second": 1908.249,
      "eval_steps_per_second": 119.325,
      "step": 12096
    },
    {
      "epoch": 12.003968253968255,
      "grad_norm": 0.0013649864122271538,
      "learning_rate": 8.003968253968254e-06,
      "loss": 0.022,
      "step": 12100
    },
    {
      "epoch": 12.053571428571429,
      "grad_norm": 0.001027613296173513,
      "learning_rate": 7.95436507936508e-06,
      "loss": 0.0207,
      "step": 12150
    },
    {
      "epoch": 12.103174603174603,
      "grad_norm": 0.0010308296186849475,
      "learning_rate": 7.904761904761904e-06,
      "loss": 0.0001,
      "step": 12200
    },
    {
      "epoch": 12.152777777777779,
      "grad_norm": 0.13077867031097412,
      "learning_rate": 7.85515873015873e-06,
      "loss": 0.0036,
      "step": 12250
    },
    {
      "epoch": 12.202380952380953,
      "grad_norm": 0.005101858172565699,
      "learning_rate": 7.805555555555556e-06,
      "loss": 0.0038,
      "step": 12300
    },
    {
      "epoch": 12.251984126984127,
      "grad_norm": 0.006856120657175779,
      "learning_rate": 7.755952380952382e-06,
      "loss": 0.058,
      "step": 12350
    },
    {
      "epoch": 12.301587301587302,
      "grad_norm": 0.0022255906369537115,
      "learning_rate": 7.706349206349208e-06,
      "loss": 0.0167,
      "step": 12400
    },
    {
      "epoch": 12.351190476190476,
      "grad_norm": 0.0019198391819372773,
      "learning_rate": 7.656746031746032e-06,
      "loss": 0.0212,
      "step": 12450
    },
    {
      "epoch": 12.40079365079365,
      "grad_norm": 0.0006520267925225198,
      "learning_rate": 7.6071428571428575e-06,
      "loss": 0.037,
      "step": 12500
    },
    {
      "epoch": 12.450396825396826,
      "grad_norm": 0.0065104165114462376,
      "learning_rate": 7.557539682539683e-06,
      "loss": 0.0395,
      "step": 12550
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.785173773765564,
      "learning_rate": 7.5079365079365085e-06,
      "loss": 0.0228,
      "step": 12600
    },
    {
      "epoch": 12.549603174603174,
      "grad_norm": 0.8734153509140015,
      "learning_rate": 7.4583333333333345e-06,
      "loss": 0.0417,
      "step": 12650
    },
    {
      "epoch": 12.59920634920635,
      "grad_norm": 72.06436157226562,
      "learning_rate": 7.40873015873016e-06,
      "loss": 0.0068,
      "step": 12700
    },
    {
      "epoch": 12.648809523809524,
      "grad_norm": 0.4019917845726013,
      "learning_rate": 7.3591269841269855e-06,
      "loss": 0.0048,
      "step": 12750
    },
    {
      "epoch": 12.698412698412698,
      "grad_norm": 22.400230407714844,
      "learning_rate": 7.30952380952381e-06,
      "loss": 0.0263,
      "step": 12800
    },
    {
      "epoch": 12.748015873015873,
      "grad_norm": 0.0007129081641323864,
      "learning_rate": 7.259920634920635e-06,
      "loss": 0.0152,
      "step": 12850
    },
    {
      "epoch": 12.797619047619047,
      "grad_norm": 0.0016693611396476626,
      "learning_rate": 7.2113095238095244e-06,
      "loss": 0.0393,
      "step": 12900
    },
    {
      "epoch": 12.847222222222221,
      "grad_norm": 0.07085379213094711,
      "learning_rate": 7.1617063492063495e-06,
      "loss": 0.0297,
      "step": 12950
    },
    {
      "epoch": 12.896825396825397,
      "grad_norm": 0.000599152292124927,
      "learning_rate": 7.1121031746031755e-06,
      "loss": 0.0079,
      "step": 13000
    },
    {
      "epoch": 12.946428571428571,
      "grad_norm": 0.025695011019706726,
      "learning_rate": 7.062500000000001e-06,
      "loss": 0.0336,
      "step": 13050
    },
    {
      "epoch": 12.996031746031747,
      "grad_norm": 0.18048986792564392,
      "learning_rate": 7.012896825396826e-06,
      "loss": 0.0121,
      "step": 13100
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.7612903225806451,
      "eval_loss": 2.0712978839874268,
      "eval_runtime": 2.1176,
      "eval_samples_per_second": 1903.064,
      "eval_steps_per_second": 119.001,
      "step": 13104
    },
    {
      "epoch": 13.045634920634921,
      "grad_norm": 0.006146721541881561,
      "learning_rate": 6.963293650793651e-06,
      "loss": 0.005,
      "step": 13150
    },
    {
      "epoch": 13.095238095238095,
      "grad_norm": 0.014120150357484818,
      "learning_rate": 6.913690476190477e-06,
      "loss": 0.0091,
      "step": 13200
    },
    {
      "epoch": 13.14484126984127,
      "grad_norm": 0.0007666033343411982,
      "learning_rate": 6.864087301587302e-06,
      "loss": 0.0054,
      "step": 13250
    },
    {
      "epoch": 13.194444444444445,
      "grad_norm": 0.004313662648200989,
      "learning_rate": 6.814484126984128e-06,
      "loss": 0.0219,
      "step": 13300
    },
    {
      "epoch": 13.244047619047619,
      "grad_norm": 0.6858428716659546,
      "learning_rate": 6.764880952380954e-06,
      "loss": 0.0173,
      "step": 13350
    },
    {
      "epoch": 13.293650793650794,
      "grad_norm": 0.0007860296173021197,
      "learning_rate": 6.715277777777778e-06,
      "loss": 0.0096,
      "step": 13400
    },
    {
      "epoch": 13.343253968253968,
      "grad_norm": 0.0005948609323240817,
      "learning_rate": 6.665674603174603e-06,
      "loss": 0.0164,
      "step": 13450
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.002146427985280752,
      "learning_rate": 6.616071428571429e-06,
      "loss": 0.0229,
      "step": 13500
    },
    {
      "epoch": 13.442460317460318,
      "grad_norm": 0.005605942569673061,
      "learning_rate": 6.566468253968255e-06,
      "loss": 0.0173,
      "step": 13550
    },
    {
      "epoch": 13.492063492063492,
      "grad_norm": 29.010778427124023,
      "learning_rate": 6.51686507936508e-06,
      "loss": 0.02,
      "step": 13600
    },
    {
      "epoch": 13.541666666666666,
      "grad_norm": 0.0005720589542761445,
      "learning_rate": 6.467261904761906e-06,
      "loss": 0.0351,
      "step": 13650
    },
    {
      "epoch": 13.591269841269842,
      "grad_norm": 0.01122375950217247,
      "learning_rate": 6.417658730158731e-06,
      "loss": 0.0354,
      "step": 13700
    },
    {
      "epoch": 13.640873015873016,
      "grad_norm": 0.0008480864344164729,
      "learning_rate": 6.368055555555555e-06,
      "loss": 0.0102,
      "step": 13750
    },
    {
      "epoch": 13.69047619047619,
      "grad_norm": 0.0009047766216099262,
      "learning_rate": 6.318452380952381e-06,
      "loss": 0.0242,
      "step": 13800
    },
    {
      "epoch": 13.740079365079366,
      "grad_norm": 0.0012880751164630055,
      "learning_rate": 6.26984126984127e-06,
      "loss": 0.002,
      "step": 13850
    },
    {
      "epoch": 13.78968253968254,
      "grad_norm": 0.0007573941838927567,
      "learning_rate": 6.220238095238096e-06,
      "loss": 0.0114,
      "step": 13900
    },
    {
      "epoch": 13.839285714285714,
      "grad_norm": 0.0009426092728972435,
      "learning_rate": 6.170634920634922e-06,
      "loss": 0.0008,
      "step": 13950
    },
    {
      "epoch": 13.88888888888889,
      "grad_norm": 0.2724629342556,
      "learning_rate": 6.121031746031747e-06,
      "loss": 0.0211,
      "step": 14000
    },
    {
      "epoch": 13.938492063492063,
      "grad_norm": 0.013424048200249672,
      "learning_rate": 6.071428571428571e-06,
      "loss": 0.0009,
      "step": 14050
    },
    {
      "epoch": 13.988095238095237,
      "grad_norm": 97.91046142578125,
      "learning_rate": 6.021825396825397e-06,
      "loss": 0.0272,
      "step": 14100
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.758560794044665,
      "eval_loss": 2.163541793823242,
      "eval_runtime": 2.1155,
      "eval_samples_per_second": 1904.985,
      "eval_steps_per_second": 119.121,
      "step": 14112
    },
    {
      "epoch": 14.037698412698413,
      "grad_norm": 0.033446770161390305,
      "learning_rate": 5.972222222222222e-06,
      "loss": 0.0207,
      "step": 14150
    },
    {
      "epoch": 14.087301587301587,
      "grad_norm": 0.0007424557697959244,
      "learning_rate": 5.922619047619048e-06,
      "loss": 0.0041,
      "step": 14200
    },
    {
      "epoch": 14.136904761904763,
      "grad_norm": 0.00041356103611178696,
      "learning_rate": 5.873015873015874e-06,
      "loss": 0.0143,
      "step": 14250
    },
    {
      "epoch": 14.186507936507937,
      "grad_norm": 0.0005291178822517395,
      "learning_rate": 5.823412698412699e-06,
      "loss": 0.0309,
      "step": 14300
    },
    {
      "epoch": 14.23611111111111,
      "grad_norm": 0.0011819539358839393,
      "learning_rate": 5.773809523809523e-06,
      "loss": 0.0261,
      "step": 14350
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.0030900337733328342,
      "learning_rate": 5.724206349206349e-06,
      "loss": 0.0004,
      "step": 14400
    },
    {
      "epoch": 14.33531746031746,
      "grad_norm": 0.0006822517607361078,
      "learning_rate": 5.674603174603175e-06,
      "loss": 0.0145,
      "step": 14450
    },
    {
      "epoch": 14.384920634920634,
      "grad_norm": 0.000992869259789586,
      "learning_rate": 5.625e-06,
      "loss": 0.0131,
      "step": 14500
    },
    {
      "epoch": 14.43452380952381,
      "grad_norm": 0.0031435959972441196,
      "learning_rate": 5.575396825396826e-06,
      "loss": 0.0021,
      "step": 14550
    },
    {
      "epoch": 14.484126984126984,
      "grad_norm": 0.06647929549217224,
      "learning_rate": 5.525793650793651e-06,
      "loss": 0.0148,
      "step": 14600
    },
    {
      "epoch": 14.533730158730158,
      "grad_norm": 0.0006155046285130084,
      "learning_rate": 5.476190476190477e-06,
      "loss": 0.0165,
      "step": 14650
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 2.9246652126312256,
      "learning_rate": 5.4265873015873016e-06,
      "loss": 0.0088,
      "step": 14700
    },
    {
      "epoch": 14.632936507936508,
      "grad_norm": 0.16429239511489868,
      "learning_rate": 5.3769841269841275e-06,
      "loss": 0.0216,
      "step": 14750
    },
    {
      "epoch": 14.682539682539682,
      "grad_norm": 0.0005420434754341841,
      "learning_rate": 5.327380952380953e-06,
      "loss": 0.0128,
      "step": 14800
    },
    {
      "epoch": 14.732142857142858,
      "grad_norm": 0.7717035412788391,
      "learning_rate": 5.2777777777777785e-06,
      "loss": 0.0225,
      "step": 14850
    },
    {
      "epoch": 14.781746031746032,
      "grad_norm": 0.00076672324212268,
      "learning_rate": 5.228174603174604e-06,
      "loss": 0.0181,
      "step": 14900
    },
    {
      "epoch": 14.831349206349206,
      "grad_norm": 0.0005349658895283937,
      "learning_rate": 5.1785714285714296e-06,
      "loss": 0.0083,
      "step": 14950
    },
    {
      "epoch": 14.880952380952381,
      "grad_norm": 0.004029339645057917,
      "learning_rate": 5.128968253968254e-06,
      "loss": 0.0164,
      "step": 15000
    },
    {
      "epoch": 14.930555555555555,
      "grad_norm": 0.0010477298637852073,
      "learning_rate": 5.07936507936508e-06,
      "loss": 0.0376,
      "step": 15050
    },
    {
      "epoch": 14.98015873015873,
      "grad_norm": 0.0019673502538353205,
      "learning_rate": 5.029761904761905e-06,
      "loss": 0.0031,
      "step": 15100
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.7660049627791563,
      "eval_loss": 2.121528148651123,
      "eval_runtime": 2.2377,
      "eval_samples_per_second": 1800.944,
      "eval_steps_per_second": 112.615,
      "step": 15120
    },
    {
      "epoch": 15.029761904761905,
      "grad_norm": 0.000607656198553741,
      "learning_rate": 4.980158730158731e-06,
      "loss": 0.0121,
      "step": 15150
    },
    {
      "epoch": 15.079365079365079,
      "grad_norm": 0.0012586896773427725,
      "learning_rate": 4.930555555555556e-06,
      "loss": 0.0086,
      "step": 15200
    },
    {
      "epoch": 15.128968253968255,
      "grad_norm": 0.0009428347111679614,
      "learning_rate": 4.880952380952381e-06,
      "loss": 0.0015,
      "step": 15250
    },
    {
      "epoch": 15.178571428571429,
      "grad_norm": 0.00100325932726264,
      "learning_rate": 4.831349206349207e-06,
      "loss": 0.0003,
      "step": 15300
    },
    {
      "epoch": 15.228174603174603,
      "grad_norm": 0.0004145293787587434,
      "learning_rate": 4.781746031746032e-06,
      "loss": 0.0007,
      "step": 15350
    },
    {
      "epoch": 15.277777777777779,
      "grad_norm": 0.0006788512109778821,
      "learning_rate": 4.732142857142857e-06,
      "loss": 0.0149,
      "step": 15400
    },
    {
      "epoch": 15.327380952380953,
      "grad_norm": 0.0005684707430191338,
      "learning_rate": 4.682539682539683e-06,
      "loss": 0.0084,
      "step": 15450
    },
    {
      "epoch": 15.376984126984127,
      "grad_norm": 1.7020621299743652,
      "learning_rate": 4.632936507936508e-06,
      "loss": 0.0133,
      "step": 15500
    },
    {
      "epoch": 15.426587301587302,
      "grad_norm": 0.0009523332701064646,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.002,
      "step": 15550
    },
    {
      "epoch": 15.476190476190476,
      "grad_norm": 111.13668060302734,
      "learning_rate": 4.533730158730159e-06,
      "loss": 0.0079,
      "step": 15600
    },
    {
      "epoch": 15.52579365079365,
      "grad_norm": 0.0003387119504623115,
      "learning_rate": 4.484126984126984e-06,
      "loss": 0.0098,
      "step": 15650
    },
    {
      "epoch": 15.575396825396826,
      "grad_norm": 0.0010339360451325774,
      "learning_rate": 4.434523809523809e-06,
      "loss": 0.025,
      "step": 15700
    },
    {
      "epoch": 15.625,
      "grad_norm": 0.0005609922809526324,
      "learning_rate": 4.384920634920635e-06,
      "loss": 0.0262,
      "step": 15750
    },
    {
      "epoch": 15.674603174603174,
      "grad_norm": 0.0005197696154937148,
      "learning_rate": 4.335317460317461e-06,
      "loss": 0.014,
      "step": 15800
    },
    {
      "epoch": 15.72420634920635,
      "grad_norm": 0.00037516216980293393,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.0034,
      "step": 15850
    },
    {
      "epoch": 15.773809523809524,
      "grad_norm": 0.002402647165581584,
      "learning_rate": 4.236111111111111e-06,
      "loss": 0.0264,
      "step": 15900
    },
    {
      "epoch": 15.823412698412698,
      "grad_norm": 0.0006238429341465235,
      "learning_rate": 4.186507936507937e-06,
      "loss": 0.013,
      "step": 15950
    },
    {
      "epoch": 15.873015873015873,
      "grad_norm": 0.033559687435626984,
      "learning_rate": 4.136904761904762e-06,
      "loss": 0.0418,
      "step": 16000
    },
    {
      "epoch": 15.922619047619047,
      "grad_norm": 14.270143508911133,
      "learning_rate": 4.0873015873015875e-06,
      "loss": 0.0078,
      "step": 16050
    },
    {
      "epoch": 15.972222222222221,
      "grad_norm": 0.0015551919350400567,
      "learning_rate": 4.0376984126984135e-06,
      "loss": 0.0004,
      "step": 16100
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.7617866004962779,
      "eval_loss": 2.2122788429260254,
      "eval_runtime": 2.1102,
      "eval_samples_per_second": 1909.803,
      "eval_steps_per_second": 119.422,
      "step": 16128
    },
    {
      "epoch": 16.021825396825395,
      "grad_norm": 0.0006525956559926271,
      "learning_rate": 3.9880952380952386e-06,
      "loss": 0.0018,
      "step": 16150
    },
    {
      "epoch": 16.071428571428573,
      "grad_norm": 0.0005285314400680363,
      "learning_rate": 3.938492063492064e-06,
      "loss": 0.0027,
      "step": 16200
    },
    {
      "epoch": 16.121031746031747,
      "grad_norm": 18.59150505065918,
      "learning_rate": 3.88888888888889e-06,
      "loss": 0.0179,
      "step": 16250
    },
    {
      "epoch": 16.17063492063492,
      "grad_norm": 0.006591993849724531,
      "learning_rate": 3.839285714285715e-06,
      "loss": 0.0119,
      "step": 16300
    },
    {
      "epoch": 16.220238095238095,
      "grad_norm": 0.0005148010677658021,
      "learning_rate": 3.7896825396825398e-06,
      "loss": 0.002,
      "step": 16350
    },
    {
      "epoch": 16.26984126984127,
      "grad_norm": 0.0005368569400161505,
      "learning_rate": 3.7400793650793653e-06,
      "loss": 0.0024,
      "step": 16400
    },
    {
      "epoch": 16.319444444444443,
      "grad_norm": 0.0005518906400538981,
      "learning_rate": 3.690476190476191e-06,
      "loss": 0.0098,
      "step": 16450
    },
    {
      "epoch": 16.36904761904762,
      "grad_norm": 0.020195666700601578,
      "learning_rate": 3.640873015873016e-06,
      "loss": 0.0047,
      "step": 16500
    },
    {
      "epoch": 16.418650793650794,
      "grad_norm": 0.0006379710976034403,
      "learning_rate": 3.592261904761905e-06,
      "loss": 0.0243,
      "step": 16550
    },
    {
      "epoch": 16.46825396825397,
      "grad_norm": 51.153316497802734,
      "learning_rate": 3.5426587301587306e-06,
      "loss": 0.0101,
      "step": 16600
    },
    {
      "epoch": 16.517857142857142,
      "grad_norm": 0.0493076890707016,
      "learning_rate": 3.4930555555555557e-06,
      "loss": 0.0128,
      "step": 16650
    },
    {
      "epoch": 16.567460317460316,
      "grad_norm": 0.0003807772882282734,
      "learning_rate": 3.443452380952381e-06,
      "loss": 0.0092,
      "step": 16700
    },
    {
      "epoch": 16.617063492063494,
      "grad_norm": 0.002045025583356619,
      "learning_rate": 3.3938492063492067e-06,
      "loss": 0.0017,
      "step": 16750
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 3.6976521015167236,
      "learning_rate": 3.3442460317460318e-06,
      "loss": 0.0263,
      "step": 16800
    },
    {
      "epoch": 16.716269841269842,
      "grad_norm": 0.010098500177264214,
      "learning_rate": 3.2946428571428573e-06,
      "loss": 0.0089,
      "step": 16850
    },
    {
      "epoch": 16.765873015873016,
      "grad_norm": 0.000423402147134766,
      "learning_rate": 3.245039682539683e-06,
      "loss": 0.0278,
      "step": 16900
    },
    {
      "epoch": 16.81547619047619,
      "grad_norm": 0.000530279881786555,
      "learning_rate": 3.195436507936508e-06,
      "loss": 0.0018,
      "step": 16950
    },
    {
      "epoch": 16.865079365079364,
      "grad_norm": 0.03987577557563782,
      "learning_rate": 3.1458333333333334e-06,
      "loss": 0.005,
      "step": 17000
    },
    {
      "epoch": 16.91468253968254,
      "grad_norm": 0.0004213653737679124,
      "learning_rate": 3.096230158730159e-06,
      "loss": 0.0024,
      "step": 17050
    },
    {
      "epoch": 16.964285714285715,
      "grad_norm": 0.00112193264067173,
      "learning_rate": 3.046626984126984e-06,
      "loss": 0.0132,
      "step": 17100
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.7632754342431762,
      "eval_loss": 2.212200403213501,
      "eval_runtime": 2.0975,
      "eval_samples_per_second": 1921.297,
      "eval_steps_per_second": 120.141,
      "step": 17136
    },
    {
      "epoch": 17.01388888888889,
      "grad_norm": 0.002138082403689623,
      "learning_rate": 2.9970238095238095e-06,
      "loss": 0.0,
      "step": 17150
    },
    {
      "epoch": 17.063492063492063,
      "grad_norm": 0.0007228801841847599,
      "learning_rate": 2.947420634920635e-06,
      "loss": 0.022,
      "step": 17200
    },
    {
      "epoch": 17.113095238095237,
      "grad_norm": 0.0011568873887881637,
      "learning_rate": 2.897817460317461e-06,
      "loss": 0.0092,
      "step": 17250
    },
    {
      "epoch": 17.16269841269841,
      "grad_norm": 0.000687437248416245,
      "learning_rate": 2.8482142857142857e-06,
      "loss": 0.0078,
      "step": 17300
    },
    {
      "epoch": 17.21230158730159,
      "grad_norm": 0.0037937818560749292,
      "learning_rate": 2.798611111111111e-06,
      "loss": 0.0122,
      "step": 17350
    },
    {
      "epoch": 17.261904761904763,
      "grad_norm": 0.008115815930068493,
      "learning_rate": 2.749007936507937e-06,
      "loss": 0.0026,
      "step": 17400
    },
    {
      "epoch": 17.311507936507937,
      "grad_norm": 0.0012563145719468594,
      "learning_rate": 2.699404761904762e-06,
      "loss": 0.0063,
      "step": 17450
    },
    {
      "epoch": 17.36111111111111,
      "grad_norm": 0.00047415500739589334,
      "learning_rate": 2.6498015873015877e-06,
      "loss": 0.0054,
      "step": 17500
    },
    {
      "epoch": 17.410714285714285,
      "grad_norm": 0.0007138428627513349,
      "learning_rate": 2.6001984126984132e-06,
      "loss": 0.0068,
      "step": 17550
    },
    {
      "epoch": 17.46031746031746,
      "grad_norm": 0.0009374276269227266,
      "learning_rate": 2.550595238095238e-06,
      "loss": 0.0119,
      "step": 17600
    },
    {
      "epoch": 17.509920634920636,
      "grad_norm": 0.0020159666892141104,
      "learning_rate": 2.500992063492064e-06,
      "loss": 0.0007,
      "step": 17650
    },
    {
      "epoch": 17.55952380952381,
      "grad_norm": 0.08881529420614243,
      "learning_rate": 2.451388888888889e-06,
      "loss": 0.0023,
      "step": 17700
    },
    {
      "epoch": 17.609126984126984,
      "grad_norm": 0.0008440730161964893,
      "learning_rate": 2.4017857142857145e-06,
      "loss": 0.0061,
      "step": 17750
    },
    {
      "epoch": 17.658730158730158,
      "grad_norm": 0.0013254769146442413,
      "learning_rate": 2.35218253968254e-06,
      "loss": 0.0265,
      "step": 17800
    },
    {
      "epoch": 17.708333333333332,
      "grad_norm": 0.0004860958142671734,
      "learning_rate": 2.302579365079365e-06,
      "loss": 0.0182,
      "step": 17850
    },
    {
      "epoch": 17.757936507936506,
      "grad_norm": 0.0004810401296708733,
      "learning_rate": 2.2529761904761906e-06,
      "loss": 0.0116,
      "step": 17900
    },
    {
      "epoch": 17.807539682539684,
      "grad_norm": 0.0003962139307986945,
      "learning_rate": 2.203373015873016e-06,
      "loss": 0.0078,
      "step": 17950
    },
    {
      "epoch": 17.857142857142858,
      "grad_norm": 0.0005119804991409183,
      "learning_rate": 2.1537698412698416e-06,
      "loss": 0.0002,
      "step": 18000
    },
    {
      "epoch": 17.90674603174603,
      "grad_norm": 0.000505007104948163,
      "learning_rate": 2.1041666666666667e-06,
      "loss": 0.0429,
      "step": 18050
    },
    {
      "epoch": 17.956349206349206,
      "grad_norm": 0.0008328163530677557,
      "learning_rate": 2.0545634920634922e-06,
      "loss": 0.0026,
      "step": 18100
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.7622828784119107,
      "eval_loss": 2.2323787212371826,
      "eval_runtime": 2.1106,
      "eval_samples_per_second": 1909.378,
      "eval_steps_per_second": 119.395,
      "step": 18144
    },
    {
      "epoch": 18.00595238095238,
      "grad_norm": 0.00043617168557830155,
      "learning_rate": 2.0049603174603177e-06,
      "loss": 0.028,
      "step": 18150
    },
    {
      "epoch": 18.055555555555557,
      "grad_norm": 0.0006719254306517541,
      "learning_rate": 1.955357142857143e-06,
      "loss": 0.0025,
      "step": 18200
    },
    {
      "epoch": 18.10515873015873,
      "grad_norm": 108.1866683959961,
      "learning_rate": 1.9057539682539683e-06,
      "loss": 0.0129,
      "step": 18250
    },
    {
      "epoch": 18.154761904761905,
      "grad_norm": 0.0018227463588118553,
      "learning_rate": 1.8561507936507939e-06,
      "loss": 0.0013,
      "step": 18300
    },
    {
      "epoch": 18.20436507936508,
      "grad_norm": 0.00048135893302969635,
      "learning_rate": 1.8065476190476192e-06,
      "loss": 0.0012,
      "step": 18350
    },
    {
      "epoch": 18.253968253968253,
      "grad_norm": 0.00042933865915983915,
      "learning_rate": 1.7569444444444445e-06,
      "loss": 0.002,
      "step": 18400
    },
    {
      "epoch": 18.303571428571427,
      "grad_norm": 0.00036772756720893085,
      "learning_rate": 1.70734126984127e-06,
      "loss": 0.0023,
      "step": 18450
    },
    {
      "epoch": 18.353174603174605,
      "grad_norm": 0.0003879160503856838,
      "learning_rate": 1.6577380952380953e-06,
      "loss": 0.002,
      "step": 18500
    },
    {
      "epoch": 18.40277777777778,
      "grad_norm": 0.00043569019180722535,
      "learning_rate": 1.6081349206349208e-06,
      "loss": 0.0116,
      "step": 18550
    },
    {
      "epoch": 18.452380952380953,
      "grad_norm": 0.000580871244892478,
      "learning_rate": 1.5585317460317461e-06,
      "loss": 0.0095,
      "step": 18600
    },
    {
      "epoch": 18.501984126984127,
      "grad_norm": 0.0004108400025870651,
      "learning_rate": 1.5089285714285714e-06,
      "loss": 0.0001,
      "step": 18650
    },
    {
      "epoch": 18.5515873015873,
      "grad_norm": 0.0006186222308315337,
      "learning_rate": 1.4593253968253971e-06,
      "loss": 0.0002,
      "step": 18700
    },
    {
      "epoch": 18.601190476190474,
      "grad_norm": 0.0016758162528276443,
      "learning_rate": 1.4097222222222222e-06,
      "loss": 0.0113,
      "step": 18750
    },
    {
      "epoch": 18.650793650793652,
      "grad_norm": 0.00034796292311511934,
      "learning_rate": 1.3601190476190475e-06,
      "loss": 0.0043,
      "step": 18800
    },
    {
      "epoch": 18.700396825396826,
      "grad_norm": 0.004098191391676664,
      "learning_rate": 1.3105158730158733e-06,
      "loss": 0.0034,
      "step": 18850
    },
    {
      "epoch": 18.75,
      "grad_norm": 0.00033632517443038523,
      "learning_rate": 1.2609126984126986e-06,
      "loss": 0.0089,
      "step": 18900
    },
    {
      "epoch": 18.799603174603174,
      "grad_norm": 0.0007582675316371024,
      "learning_rate": 1.2113095238095239e-06,
      "loss": 0.0005,
      "step": 18950
    },
    {
      "epoch": 18.849206349206348,
      "grad_norm": 0.040872227400541306,
      "learning_rate": 1.1617063492063494e-06,
      "loss": 0.0039,
      "step": 19000
    },
    {
      "epoch": 18.898809523809526,
      "grad_norm": 120.99466705322266,
      "learning_rate": 1.1121031746031747e-06,
      "loss": 0.0072,
      "step": 19050
    },
    {
      "epoch": 18.9484126984127,
      "grad_norm": 0.000589809671510011,
      "learning_rate": 1.0625e-06,
      "loss": 0.0009,
      "step": 19100
    },
    {
      "epoch": 18.998015873015873,
      "grad_norm": 0.0005369826685637236,
      "learning_rate": 1.0128968253968255e-06,
      "loss": 0.0112,
      "step": 19150
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.7615384615384615,
      "eval_loss": 2.284494638442993,
      "eval_runtime": 2.1101,
      "eval_samples_per_second": 1909.879,
      "eval_steps_per_second": 119.427,
      "step": 19152
    },
    {
      "epoch": 19.047619047619047,
      "grad_norm": 0.0006097741425037384,
      "learning_rate": 9.63293650793651e-07,
      "loss": 0.0002,
      "step": 19200
    },
    {
      "epoch": 19.09722222222222,
      "grad_norm": 1.3738088607788086,
      "learning_rate": 9.136904761904762e-07,
      "loss": 0.0091,
      "step": 19250
    },
    {
      "epoch": 19.146825396825395,
      "grad_norm": 0.015360846184194088,
      "learning_rate": 8.640873015873016e-07,
      "loss": 0.0025,
      "step": 19300
    },
    {
      "epoch": 19.196428571428573,
      "grad_norm": 0.00029771184199489653,
      "learning_rate": 8.14484126984127e-07,
      "loss": 0.0018,
      "step": 19350
    },
    {
      "epoch": 19.246031746031747,
      "grad_norm": 0.0009724196279421449,
      "learning_rate": 7.648809523809524e-07,
      "loss": 0.0005,
      "step": 19400
    },
    {
      "epoch": 19.29563492063492,
      "grad_norm": 0.005197130609303713,
      "learning_rate": 7.152777777777778e-07,
      "loss": 0.0,
      "step": 19450
    },
    {
      "epoch": 19.345238095238095,
      "grad_norm": 0.00037996453465893865,
      "learning_rate": 6.656746031746033e-07,
      "loss": 0.002,
      "step": 19500
    },
    {
      "epoch": 19.39484126984127,
      "grad_norm": 0.0003406180767342448,
      "learning_rate": 6.160714285714287e-07,
      "loss": 0.0014,
      "step": 19550
    },
    {
      "epoch": 19.444444444444443,
      "grad_norm": 0.00026876950869336724,
      "learning_rate": 5.66468253968254e-07,
      "loss": 0.0119,
      "step": 19600
    },
    {
      "epoch": 19.49404761904762,
      "grad_norm": 0.0005471997428685427,
      "learning_rate": 5.168650793650794e-07,
      "loss": 0.0018,
      "step": 19650
    },
    {
      "epoch": 19.543650793650794,
      "grad_norm": 0.0005613384419120848,
      "learning_rate": 4.672619047619048e-07,
      "loss": 0.0002,
      "step": 19700
    },
    {
      "epoch": 19.59325396825397,
      "grad_norm": 0.00035296278656460345,
      "learning_rate": 4.1865079365079365e-07,
      "loss": 0.006,
      "step": 19750
    },
    {
      "epoch": 19.642857142857142,
      "grad_norm": 0.0007682198192924261,
      "learning_rate": 3.6904761904761906e-07,
      "loss": 0.0018,
      "step": 19800
    },
    {
      "epoch": 19.692460317460316,
      "grad_norm": 0.001223155064508319,
      "learning_rate": 3.1944444444444447e-07,
      "loss": 0.0,
      "step": 19850
    },
    {
      "epoch": 19.742063492063494,
      "grad_norm": 0.022004827857017517,
      "learning_rate": 2.698412698412699e-07,
      "loss": 0.0006,
      "step": 19900
    },
    {
      "epoch": 19.791666666666668,
      "grad_norm": 0.0018792530754581094,
      "learning_rate": 2.2023809523809526e-07,
      "loss": 0.0112,
      "step": 19950
    },
    {
      "epoch": 19.841269841269842,
      "grad_norm": 0.0005891459295526147,
      "learning_rate": 1.7063492063492064e-07,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 19.890873015873016,
      "grad_norm": 0.0019091665744781494,
      "learning_rate": 1.2103174603174605e-07,
      "loss": 0.0007,
      "step": 20050
    },
    {
      "epoch": 19.94047619047619,
      "grad_norm": 0.00025757282855920494,
      "learning_rate": 7.142857142857144e-08,
      "loss": 0.0034,
      "step": 20100
    },
    {
      "epoch": 19.990079365079364,
      "grad_norm": 0.0003578188188839704,
      "learning_rate": 2.1825396825396826e-08,
      "loss": 0.0046,
      "step": 20150
    }
  ],
  "logging_steps": 50,
  "max_steps": 20160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.067554765768704e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
